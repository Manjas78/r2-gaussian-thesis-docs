{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":""},{"location":"#bachelor-thesis","title":"BACHELOR THESIS","text":""},{"location":"#cone-beam-ct-reconstruction-using-gaussian-splatting-implementation-and-evaluation-for-preclinical-mouse-imaging","title":"Cone-Beam CT Reconstruction Using Gaussian Splatting  Implementation and Evaluation for Preclinical Mouse Imaging","text":"<p>Faculty of Engineering Sciences</p> <p>Degree Program: Interdisciplinary Engineering Sciences</p> <p>Specialization: Medical Engineering</p> <p>Prepared at: the Laboratory for Medical Imaging and Diagnostics, Hochschule RheinMain, Campus R\u00fcsselsheim; for the Research Division of Neuroradiology, University Medical Center of the Johannes Gutenberg University Mainz</p>"},{"location":"#author-manuel-robert-handta","title":"Author: Manuel Robert Handta","text":"<p>Supervisor: Prof. Dr. Bernd Schweizer</p> <p>Co-Supervisor: Dr. rer. physiol. Andrea Kronfeld</p> <p>This documentation presents a condensed summary of my Bachelor\u2019s thesis on CBCT reconstruction with the R\u00b2-Gaussian algorithm. The method of Zha et al. (2024) applies Gaussian splatting to tomographic projection data, offering a modern alternative to analytic and iterative reconstructions.</p> <p>In this thesis, the original implementation was reproduced, adapted, and tested on multiple preclinical mouse datasets to assess:</p> <ul> <li>reconstruction quality under realistic imaging constraints,</li> <li>the effect of critical hyperparameters, and</li> <li>differences in performance compared to Standard FDK Reconstruction.</li> </ul>"},{"location":"#abstract","title":"Abstract","text":"<p>This thesis evaluates the applicability of the R2-Gaussian reconstruction algorithm for preclinical cone-beam CT (CBCT) using three complementary datasets: a self-fabricated mouse phantom, the Digimouse atlas as known ground truth, and real preclinical mouse scans from UKMZ. The complete reconstruction pipeline was implemented and adapted to the constraints of an 8GB Graphics Processing Unit (GPU), requiring custom preprocessing, geometry con guration, and troubleshooting of voxelizer-related memory limitations. </p> <p>Across all experiments, R2-Gaussian produced stable reconstructions and showed clear advantages over FDK in extremely sparse-view settings. However, reconstruction quality was fundamentally limited by the maximum feasible number of Gaussians (\u2264200k), forced projection downsampling, and early termination of densi cation due to voxelization-induced out-of-memory errors. On the Digimouse phantom, performance was further restricted by the atlas\u2019 homogeneous attenuation structure, while on UKMZ data the algorithm reconstructed global anatomy but saturated once its representational capacity was reached.</p> <p>Limited-angle tests showed partial mitigation of directional artefacts, but the method could not overcome the information loss of a 190\u00b0 trajectory. The molded phantom experiments validated the full end-to-end work ow despite fabrication inaccuracies and geometric misalignment. Additionally, TIGRE-based FDK reconstructions successfully avoided the streak artefact currently present in UKMZ\u2019s local pipeline, eliminating the need for Clari post-processing. </p> <p>Overall, the results indicate that Gaussian Splatting is promising for low-dose and sparse view preclinical CT but strongly dependent on GPU memory. Larger Video Random Access Memory (VRAM) budgets and improved voxelization strategies are expected to substantially improve performance in future work.</p>"},{"location":"#reference","title":"Reference","text":"<p>original algorithm</p> <p>Ruyi Zha, Tao Jun Lin, Yuanhao Cai, Jiwen Cao, Yanhao Zhang, and Hongdong Li. R\u00b2-Gaussian: Rectifying Radiative Gaussian Splatting for Tomographic Reconstruction. Advances in Neural Information Processing Systems (NeurIPS), 2024. Paper link (arXiv)</p> <p>BibTeX: <pre><code>@inproceedings{r2_gaussian,\n  title     = {R$^2$-Gaussian: Rectifying Radiative Gaussian Splatting for Tomographic Reconstruction},\n  author    = {Ruyi Zha and Tao Jun Lin and Yuanhao Cai and Jiwen Cao and Yanhao Zhang and Hongdong Li},\n  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},\n  year      = {2024}\n}\n</code></pre></p>"},{"location":"references/","title":"References","text":"<pre><code>@article{bagAktuellerStandMikroCT2010,\n    title = {Aktueller Stand der Mikro-CT in der experimentellen Kleintierbildgebung},\n    author = {Bag, S. and Schambach, S. J. and Boll, H. and Schilling, L. and Groden, C. and Brockmann, M. A.},\n    date = {2010-05},\n    journaltitle = {R\u00f6Fo - Fortschritte auf dem Gebiet der R\u00f6ntgenstrahlen und der bildgebenden Verfahren},\n    shortjournal = {Rofo},\n    volume = {182},\n    number = {05},\n    pages = {390--403},\n    publisher = {\u00a9 Georg Thieme Verlag KG Stuttgart \u00b7 New York},\n    issn = {1438-9029, 1438-9010},\n    doi = {10.1055/s-0029-1245301},\n    abstract = {Thieme E-Books \\&amp; E-Journals},\n    langid = {ngerman}\n}\n\n@software{openaiChatGPT2025,\n    title        = {ChatGPT (GPT{\\textendash}5.1 Model)},\n    author       = {{OpenAI}},\n    date         = {2025},\n    url          = {https://chat.openai.com},\n    note         = {Large language model used to assist with text generation and editing},\n    version      = {GPT-5.1},\n    langid       = {english}\n}\n\n@online{4RPrinciple,\n    title = {4R-Principle},\n    url = {https://www.mpg.de/10973438/4rs},\n    urldate = {2025-11-27},\n    abstract = {The scientists at the Max Planck Society are committed to keeping the number of animal experiments as well as the strain on the animals as low as possible in the individual experiments. They apply the so-called 3R principle when planning and carrying out the experiments. '3R' stands for \"Reduce, Refine, Replace\": the number of animals per experiment is reduced to the absolute minimum ('Reduction'); the performance of the experiments and the keeping of the animals optimized in such a way that the burden on the animals is as small as possible ('Refinement'); and animal experiments are replaced by alternative methods, whenever this is possible ('Replacement').},\n    langid = {english}\n}\n\n@book{buzugComputedTomographyPhoton2008,\n    title        = {Computed Tomography: From Photon Statistics to Modern Cone-Beam CT},\n    author       = {Buzug, Thorsten M.},\n    date         = {2008},\n    publisher    = {Springer Berlin Heidelberg},\n    location     = {Berlin, Heidelberg},\n    doi          = {10.1007/978-3-540-39408-2},\n    isbn         = {978-3-642-07257-4, 978-3-540-39408-2},\n    edition      = {1},\n    pagetotal    = {522},\n    langid       = {english}\n}\n\n@book{kakPrinciplesComputerizedTomographic2001,\n    title        = {Principles of Computerized Tomographic Imaging},\n    author       = {Kak, Avinash C. and Slaney, Malcolm},\n    date         = {2001},\n    publisher    = {SIAM},\n    location     = {Philadelphia},\n    doi          = {10.1137/1.9780898719277},\n    isbn         = {978-0-89871-494-3},\n    series       = {SIAM Classic in Applied Mathematics},\n    langid       = {english}\n}\n\n@book{bankmanHandbookMedicalImaging2000,\n    title        = {Handbook of Medical Imaging},\n    editor       = {Bankman, Isaac N.},\n    date         = {2000},\n    publisher    = {Academic Press},\n    location     = {San Diego},\n    isbn         = {978-0-12-077790-7},\n    series       = {Biomedical Engineering},\n    langid       = {english}\n}\n\n@online{CheetahEVOComet,\n    title = {Cheetah EVO - Comet Yxlon},\n    url = {https://yxlon.comet.tech/en/products/cheetah-evo},\n    urldate = {2025-11-27},\n    file = {C:\\Users\\manue\\Zotero\\storage\\DW76PR7D\\cheetah-evo.html}\n}\n\n@online{DICOMOverview,\n    title = {About DICOM- Overview},\n    url = {https://www.dicomstandard.org/about},\n    urldate = {2025-11-27},\n    langid = {english},\n    organization = {DICOM},\n    file = {C:\\Users\\manue\\Zotero\\storage\\ASWS6CHY\\about.html}\n}\n\n@online{Digimouse_RegistrationBiomedicalImaging,\n    title = {Digimouse Registration - Biomedical Imaging Group},\n    url = {https://neuroimage.usc.edu/neuro/Digimouse_Registration},\n    urldate = {2025-11-27},\n    file = {C:\\Users\\manue\\Zotero\\storage\\YIXXQWUU\\Digimouse_Registration.html}\n}\n\n@article{dogdasDigimouse3DWhole2007,\n    title = {Digimouse: A 3D Whole Body Mouse Atlas from CT and Cryosection Data},\n    shorttitle = {Digimouse},\n    author = {Dogdas, Belma and Stout, David and Chatziioannou, Arion F and Leahy, Richard M},\n    date = {2007-02-07},\n    journaltitle = {Physics in Medicine and Biology},\n    shortjournal = {Phys. Med. Biol.},\n    volume = {52},\n    number = {3},\n    pages = {577--587},\n    issn = {0031-9155, 1361-6560},\n    doi = {10.1088/0031-9155/52/3/003},\n    abstract = {We have constructed a three-dimensional (3D) whole body mouse atlas from coregistered x-ray CT and cryosection data of a normal nude male mouse. High quality PET, x-ray CT and cryosection images were acquired post mortem from a single mouse placed in a stereotactic frame with fiducial markers visible in all three modalities. The image data were coregistered to a common coordinate system using the fiducials and resampled to an isotropic 0.1 mm voxel size. Using interactive editing tools we segmented and labelled whole brain, cerebrum, cerebellum, olfactory bulbs, striatum, medulla, masseter muscles, eyes, lachrymal glands, heart, lungs, liver, stomach, spleen, pancreas, adrenal glands, kidneys, testes, bladder, skeleton and skin surface. The final atlas consists of the 3D volume, in which the voxels are labelled to define the anatomical structures listed above, with coregistered PET, x-ray CT and cryosection images. To illustrate use of the atlas we include simulations of 3D bioluminescence and PET image reconstruction. Optical scatter and absorption values are assigned to each organ to simulate realistic photon transport within the animal for bioluminescence imaging. Similarly, 511 keV photon attenuation values are assigned to each structure in the atlas to simulate realistic photon attenuation in PET. The Digimouse atlas and data are available at http://neuroimage.usc.edu/Digimouse.html.},\n    langid = {english},\n    file = {C:\\Users\\manue\\Zotero\\storage\\GS8VYG74\\Dogdas et al. - 2007 - Digimouse a 3D whole body mouse atlas from CT and cryosection data.pdf}\n}\n\n@online{fardoFormalEvaluationPSNR2016,\n    title = {A Formal Evaluation of PSNR as Quality Measurement Parameter for Image Segmentation Algorithms},\n    author = {Fardo, Fernando A. and Conforto, Victor H. and family=Oliveira, given=Francisco C., prefix=de, useprefix=false and Rodrigues, Paulo S.},\n    date = {2016-05-23},\n    url = {https://arxiv.org/abs/1605.07116},\n    eprint = {1605.07116},\n    eprinttype = {arXiv},\n    eprintclass = {cs},\n    doi = {10.48550/arXiv.1605.07116},\n    abstract = {Quality evaluation of image segmentation algorithms are still subject of debate and research. Currently, there is no generic metric that could be applied to any algorithm reliably. This article contains an evaluation for the PSRN (Peak Signal-To-Noise Ratio) as a metric which has been used to evaluate threshold level selection as well as the number of thresholds in the case of multi-level segmentation. The results obtained in this study suggest that the PSNR is not an adequate quality measurement for segmentation algorithms.},\n    langid = {english},\n    pubstate = {prepublished},\n    file = {C:\\Users\\manue\\Zotero\\storage\\BHPRTEJC\\Fardo et al. - 2016 - A Formal Evaluation of PSNR as Quality Measurement Parameter for Image Segmentation Algorithms.pdf}\n}\n\n@article{feldkampPracticalConebeamAlgorithm1984,\n    title = {Practical Cone-Beam Algorithm},\n    author = {Feldkamp, L. A. and Davis, L. C. and Kress, J. W.},\n    date = {1984-06-01},\n    journaltitle = {Journal of the Optical Society of America A},\n    shortjournal = {J. Opt. Soc. Am. A},\n    volume = {1},\n    number = {6},\n    pages = {612},\n    issn = {1084-7529, 1520-8532},\n    doi = {10.1364/JOSAA.1.000612},\n    langid = {english},\n    file = {C:\\Users\\manue\\Zotero\\storage\\PDXSKIQB\\Feldkamp et al. - 1984 - Practical cone-beam algorithm.pdf}\n}\n\n@software{gpricechristieGpricechristieMousePhantom2024,\n    title = {Gpricechristie/mousePhantom},\n    author = {{gpricechristie}},\n    date = {2024-08-31T07:29:14Z},\n    origdate = {2019-05-08T14:01:34Z},\n    url = {https://github.com/gpricechristie/mousePhantom},\n    urldate = {2025-11-27},\n    abstract = {Plastic mouse phantom}\n}\n\n@article{hounsfieldComputedMedicalImaging,\n    title = {Computed Medical Imaging},\n    author = {Hounsfield, Godfrey N},\n    langid = {english},\n    file = {C:\\Users\\manue\\Zotero\\storage\\AV7SBJX7\\Hounsfield - Computed Medical Imaging.pdf}\n}\n\n@article{kerbl3DGaussianSplatting2023,\n    title = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},\n    author = {Kerbl, Bernhard and Kopanas, Georgios and Leimkuehler, Thomas and Drettakis, George},\n    date = {2023-08},\n    journaltitle = {ACM Transactions on Graphics},\n    shortjournal = {ACM Trans. Graph.},\n    volume = {42},\n    number = {4},\n    pages = {1--14},\n    issn = {0730-0301, 1557-7368},\n    doi = {10.1145/3592433},\n    abstract = {Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates. We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (\u2265 30 fps) novel-view synthesis at 1080p resolution. First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.},\n    langid = {english},\n    file = {C:\\Users\\manue\\Zotero\\storage\\EHZC54CK\\Kerbl et al. - 2023 - 3D Gaussian Splatting for Real-Time Radiance Field Rendering.pdf}\n}\n\n@video{matthiasniessnerTUMAILecture2025,\n    entrysubtype = {video},\n    title = {TUM AI Lecture Series - The 3D Gaussian Splatting Adventure: Past, Present, Futur (George Drettakis)},\n    shorttitle = {TUM AI Lecture Series - The 3D Gaussian Splatting Adventure},\n    editor = {Matthias Niessner},\n    editortype = {director},\n    date = {2025-02-03},\n    url = {https://www.youtube.com/watch?v=DjOqkVIlEGY},\n    urldate = {2025-11-27},\n    abstract = {Abstract: Neural rendering has advanced at outstanding speed in recent years, with the advent}\n}\n\n@online{openai_sora2024,\n    title        = {Sora: Text-to-Video Generation Model},\n    author       = {OpenAI},\n    year         = {2024},\n    howpublished = {\\url{https://openai.com/sora}},\n    note         = {Accessed: 2025-11-28},\n    institution  = {OpenAI}\n}\n\n@online{nilssonUnderstandingSSIM2020,\n    title = {Understanding SSIM},\n    author = {Nilsson, Jim and Akenine-M\u00f6ller, Tomas},\n    date = {2020-06-29},\n    url = {https://arxiv.org/abs/2006.13846},\n    eprint = {2006.13846},\n    eprinttype = {arXiv},\n    eprintclass = {eess},\n    doi = {10.48550/arXiv.2006.13846},\n    abstract = {The use of the structural similarity index (SSIM) is widespread. For almost two decades, it has played a major role in image quality assessment in many different research disciplines. Clearly, its merits are indisputable in the research community. However, little deep scrutiny of this index has been performed. Contrary to popular belief, there are some interesting properties of SSIM that merit such scrutiny. In this paper, we analyze the mathematical factors of SSIM and show that it can generate results, in both synthetic and realistic use cases, that are unexpected, sometimes undefined, and nonintuitive. As a consequence, assessing image quality based on SSIM can lead to incorrect conclusions and using SSIM as a loss function for deep learning can guide neural network training in the wrong direction.},\n    langid = {english},\n    pubstate = {prepublished},\n    file = {C:\\Users\\manue\\Zotero\\storage\\EHXYUCYH\\Nilsson and Akenine-M\u00f6ller - 2020 - Understanding SSIM.pdf}\n}\n\n@online{PraeklinischeBildgebungKlinik,\n    title = {Pr\u00e4klinische Bildgebung \u2013 Klinik und Poliklinik f\u00fcr Neuroradiologie},\n    url = {https://www.unimedizin-mainz.de/neuroradiologie/forschung-studien/praeklinische-bildgebung.html},\n    urldate = {2025-11-27},\n    langid = {ngerman},\n    file = {C:\\Users\\manue\\Zotero\\storage\\APZ2QWG9\\praeklinische-bildgebung.html}\n}\n\n@article{priceOpenSourceHeterogeneous2020,\n    title = {An Open Source Heterogeneous 3D Printed Mouse Phantom Utilising a Novel Bone Representative Thermoplastic},\n    author = {Price, Gareth and Biglin, Emma R and Collins, Sean and Aitkinhead, Adam and Subiel, Anna and Chadwick, Amy L and Cullen, M, David and Kirkby, Karen J and Schettino, Giuseppe and Tipping, Jill and Robinson, Andrew},\n    date = {2020-05-21},\n    journaltitle = {Physics in Medicine \\&amp; Biology},\n    shortjournal = {Phys. Med. Biol.},\n    volume = {65},\n    number = {10},\n    pages = {10NT02},\n    issn = {0031-9155, 1361-6560},\n    doi = {10.1088/1361-6560/ab8078},\n    abstract = {The lack of rigorous quality standards in pre-clinical radiation dosimetry has renewed interest in the development of anthropomorphic phantoms. Using 3D printing customisable phantoms can be created to assess all parts of pre-clinical radiation research: planning, image guidance and treatment delivery. We present the full methodology, including material development and printing designs, for the production of a high spatial resolution, anatomically realistic heterogeneous small animal phantom. A methodology for creating and validating tissue equivalent materials is presented. The technique is demonstrated through the development of a bone-equivalent material. This material is used together with a soft-tissue mimicking ABS plastic filament to reproduce the corresponding structure geometries captured from a CT scan of a nude mouse. Air gaps are used to represent the lungs. Phantom validation was performed through comparison of the geometry and x-ray attenuation of CT images of the phantom and animal images. A 6.6\\% difference in the attenuation of the bone-equivalent material compared to the reference standard in softer beams (0.5 mm Cu HVL) rapidly decreases as the beam is hardened. CT imaging shows accurate (sub-millimetre) reproduction of the skeleton (Distance-To-Agreement 0.5 mm \u00b1 0.4 mm) and body surface (0.7 mm \u00b1 0.5 mm). Histograms of the voxel intensity profile of the phantom demonstrate suitable similarity to those of both the original mouse image and that of a different animal. We present an approach for the efficient production of an anthropomorphic phantom suitable for the quality assurance of pre-clinical radiotherapy. Our design and full methodology are provided as open source to encourage the pre-clinical radiobiology community to adopt a common QA standard. Abbreviations ABS \u2013 acrylonitrile butadiene styrene, CBCT \u2013 cone beam computed tomography, FDM \u2013 fused deposition modelling, HVL \u2013 half value layer, HU \u2013 Hounsfield units, ICRU - International Commission on Radiation Units and Measurements, NIST \u2013 National Institute of Standards and Technology, NPL \u2013 National Physical Laboratory, QA \u2013 quality assurance, ROI \u2013 region of interest, SARRP \u2013 small animal radiation research platform, STL \u2013 stereolithography.},\n    langid = {english},\n    file = {C:\\Users\\manue\\Zotero\\storage\\L787AGT7\\Price et al. - 2020 - An open source heterogeneous 3D printed mouse phantom utilising a novel bone representative thermopl.pdf}\n}\n\n@book{schlegelMedizinischePhysikGrundlagen2018,\n    title = {Medizinische Physik: Grundlagen \u2013 Bildgebung \u2013 Therapie \u2013 Technik},\n    shorttitle = {Medizinische Physik},\n    editor = {Schlegel, Wolfgang and Karger, Christian P. and J\u00e4kel, Oliver},\n    date = {2018},\n    publisher = {Springer Berlin Heidelberg},\n    location = {Berlin, Heidelberg},\n    doi = {10.1007/978-3-662-54801-1},\n    isbn = {978-3-662-54800-4 978-3-662-54801-1},\n    langid = {ngerman},\n    file = {C:\\Users\\manue\\Zotero\\storage\\2GQ4JVBJ\\Schlegel et al. - 2018 - Medizinische Physik Grundlagen \u2013 Bildgebung \u2013 Therapie \u2013 Technik.pdf}\n}\n\n@online{SectionalMousePhantom,\n    title = {Sectional Mouse Phantom for X-Ray and CT Scan},\n    url = {https://norecopa.no/norina/sectional-mouse-phantom-for-x-ray-and-ct-scan/},\n    urldate = {2025-11-27},\n    langid = {english},\n    file = {C:\\Users\\manue\\Zotero\\storage\\285PWEZK\\sectional-mouse-phantom-for-x-ray-and-ct-scan.html}\n}\n\n@article{zhaoGeometricParametersEstimation2015,\n    title = {Geometric Parameters Estimation and Calibration in Cone-Beam Micro-CT},\n    author = {Zhao, Jintao and Hu, Xiaodong and Zou, Jing and Hu, Xiaotang},\n    date = {2015-09-09},\n    journaltitle = {Sensors},\n    shortjournal = {Sensors},\n    volume = {15},\n    number = {9},\n    pages = {22811--22825},\n    issn = {1424-8220},\n    doi = {10.3390/s150922811},\n    abstract = {The quality of Computed Tomography (CT) images crucially depends on the precise knowledge of the scanner geometry. Therefore, it is necessary to estimate and calibrate the misalignments before image acquisition. In this paper, a Two-Piece-Ball (TPB) phantom is used to estimate a set of parameters that describe the geometry of a cone-beam CT system. Only multiple projections of the TPB phantom at one position are required, which can avoid the rotation errors when acquiring multi-angle projections. Also, a corresponding algorithm is derived. The performance of the method is evaluated through simulation and experimental data. The results demonstrated that the proposed method is valid and easy to implement. Furthermore, the experimental results from the Micro-CT system demonstrate the ability to reduce artifacts and improve image quality through geometric parameter calibration.},\n    langid = {english},\n    file = {C:\\Users\\manue\\Zotero\\storage\\AYNP2F3H\\Zhao et al. - 2015 - Geometric Parameters Estimation and Calibration in Cone-Beam Micro-CT.pdf}\n}\n\n@online{zhaR$^2$GaussianRectifyingRadiative2024,\n    title = {R\\$\\textasciicircum 2\\$-Gaussian: Rectifying Radiative Gaussian Splatting for Tomographic Reconstruction},\n    shorttitle = {R\\$\\textasciicircum 2\\$-Gaussian},\n    author = {Zha, Ruyi and Lin, Tao Jun and Cai, Yuanhao and Cao, Jiwen and Zhang, Yanhao and Li, Hongdong},\n    date = {2024-10-27},\n    eprint = {2405.20693},\n    eprinttype = {arXiv},\n    eprintclass = {eess},\n    doi = {10.48550/arXiv.2405.20693},\n    abstract = {3D Gaussian splatting (3DGS) has shown promising results in image rendering and surface reconstruction. However, its potential in volumetric reconstruction tasks, such as X-ray computed tomography, remains under-explored. This paper introduces R\\$\\textasciicircum 2\\$-Gaussian, the first 3DGS-based framework for sparse-view tomographic reconstruction. By carefully deriving X-ray rasterization functions, we discover a previously unknown integration bias in the standard 3DGS formulation, which hampers accurate volume retrieval. To address this issue, we propose a novel rectification technique via refactoring the projection from 3D to 2D Gaussians. Our new method presents three key innovations: (1) introducing tailored Gaussian kernels, (2) extending rasterization to X-ray imaging, and (3) developing a CUDA-based differentiable voxelizer. Experiments on synthetic and real-world datasets demonstrate that our method outperforms state-of-the-art approaches in accuracy and efficiency. Crucially, it delivers high-quality results in 4 minutes, which is 12\\$\\textbackslash times\\$ faster than NeRF-based methods and on par with traditional algorithms. Code and models are available on the project page https://github.com/Ruyi-Zha/r2\\_gaussian.},\n    langid = {english},\n    pubstate = {prepublished},\n    file = {C:\\Users\\manue\\Zotero\\storage\\7E5HSEI8\\Zha et al. - 2024 - R$^2$-Gaussian Rectifying Radiative Gaussian Splatting for Tomographic Reconstruction.pdf}\n}\n\n@article{zhouwangImageQualityAssessment2004,\n    title = {Image Quality Assessment: From Error Visibility to Structural Similarity},\n    shorttitle = {Image Quality Assessment},\n    author = {Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},\n    date = {2004-04},\n    journaltitle = {IEEE Transactions on Image Processing},\n    shortjournal = {IEEE Trans. on Image Process.},\n    volume = {13},\n    number = {4},\n    pages = {600--612},\n    issn = {1057-7149, 1941-0042},\n    doi = {10.1109/TIP.2003.819861}\n}\n</code></pre>"},{"location":"Conclusion/conclusion/","title":"Discussion &amp; Conclusion (Condensed)","text":"<p>Condensed Version</p> <p>The content below is a shortened summary of the original, full-length analysis. Only the key findings are included here. For complete figures, reconstruction curves, and parameter evaluations, refer to the thesis PDF.</p>"},{"location":"Conclusion/conclusion/#phantom-experiments","title":"Phantom Experiments","text":"<p>The molded mouse phantom was usable but exhibited several fabrication issues: displaced PLA/SLA components, trapped air bubbles, and imperfect axis alignment due to the object being slightly too large for the CBCT system. These factors, together with slight rotational wobble, contributed to reduced reconstruction quality. BaSO\u2084 doping increased contrast but not sufficiently to mimic realistic bone.  </p> <p>The Digimouse digital phantom provided a clean ground truth but was not ideal for R\u00b2-Gaussian because large homogeneous regions contain too few gradients to trigger effective densification. As a result, the algorithm performed worse on Digimouse than on real CBCT data.</p>"},{"location":"Conclusion/conclusion/#r2-gaussian-reconstruction-performance","title":"R\u00b2-Gaussian Reconstruction Performance","text":"<p>GPU memory was the dominant limitation. With only 8 GB VRAM, the algorithm was restricted to ~200k Gaussians\u2014far below the capacity used in the original work. At UKMZ resolution (630\u00b3 voxels), each Gaussian effectively represented hundreds of voxels, preventing high-frequency anatomical detail from being reconstructed.</p> <p>Projection downsampling (630\u00d7630 \u2192 210\u00d7210) further reduced the gradient information required for refining Gaussians. Most out-of-memory errors occurred during voxelization; a more memory-efficient voxelizer could substantially improve feasibility.  </p> <p>Qualitatively, R\u00b2-Gaussian generated smooth, noise-suppressed volumes and remained stable under extreme sparsity, but small structures and edges were consistently blurred due to the limited Gaussian budget.</p>"},{"location":"Conclusion/conclusion/#technical-limitations","title":"Technical Limitations","text":"<p>Key constraints:</p> <ul> <li>GPU memory: restricted Gaussian count, early densification stop, reduced iterations, and mandatory projection downsampling.  </li> <li>Evaluation bias: real datasets used FDK as pseudo ground truth, penalizing R\u00b2-Gaussian whenever it deviated from FDK-specific intensity scaling or artifacts.</li> </ul> <p>These factors directly limited achievable reconstruction fidelity.</p>"},{"location":"Conclusion/conclusion/#summary-of-findings","title":"Summary of Findings","text":"<p>R\u00b2-Gaussian was tested on a molded physical phantom, the Digimouse atlas, and real UKMZ mouse scans. The method produced stable reconstructions under sparse-view conditions and outperformed FDK at extremely low projection counts. On real datasets, global structure was reconstructed reliably, but improvements saturated once the Gaussian limit was reached.  </p> <p>TIGRE-based FDK reconstructions avoided the streak artifact present in UKMZ\u2019s local pipeline, removing the need for Clari post-processing. Limited-angle tests showed partial artifact mitigation but could not compensate for the intrinsic information loss of a 190\u00b0 orbit.</p> <p></p>"},{"location":"Conclusion/conclusion/#feasibility","title":"Feasibility","text":"<p>Under the hardware constraints of this work (8 GB VRAM), Gaussian Splatting is not yet feasible for high-resolution preclinical CBCT reconstruction. The representational capacity is insufficient to preserve fine anatomical detail.</p> <p>However, the method scales strongly with GPU memory. With \u226524 GB VRAM\u2014matching the hardware used in the original publication\u2014higher Gaussian budgets, complete densification schedules, and full voxelization become realistic. Under such conditions, substantially improved reconstruction quality is expected.</p>"},{"location":"Conclusion/conclusion/#lessons-learned","title":"Lessons Learned","text":"<p>This project required full end-to-end work with the R\u00b2-Gaussian pipeline, including installation, geometry configuration, CUDA debugging, and evaluation across three datasets. It strengthened practical skills in GPU-based optimization, reproducible environments (WSL2, Git, VS Code), error analysis, and CBCT acquisition using a self-built phantom.  </p> <p>AI tools were helpful for debugging and writing but required a solid understanding of the underlying code to be effective.</p>"},{"location":"Conclusion/conclusion/#outlook","title":"Outlook","text":"<p>Future improvements should focus on reducing or eliminating current hardware limitations. Promising directions include:</p> <ul> <li>Using GPUs with \u226524 GB VRAM for higher Gaussian counts  </li> <li>Full-resolution UKMZ reconstructions with increased model capacity  </li> <li>Systematic hyperparameter studies under relaxed memory constraints  </li> <li>Improved phantom design and geometric calibration  </li> <li>Automated axis-shift estimation for UKMZ\u2019s FDK workflow  </li> <li>Integration of R\u00b2-Gaussian into sparse-view or dose-reduced protocols  </li> <li>Optimizing or redesigning the voxelizer for reduced memory usage  </li> </ul> <p>Gaussian Splatting remains a promising method for low-dose and sparse-view preclinical CT, provided that sufficient GPU resources and improved voxelization strategies are available.</p>"},{"location":"experiments/experiments/","title":"Materials &amp; Methods (Condensed)","text":"<p>Condensed Version</p> <p>The content below is a shortened summary of the original, full-length analysis. Only the key findings are included here. For complete figures, reconstruction curves, and parameter evaluations, refer to the thesis PDF.</p>"},{"location":"experiments/experiments/#data-experimental-design","title":"Data &amp; Experimental Design","text":"<p>Three complementary datasets were used to evaluate R\u00b2-Gaussian against a classical FDK baseline:</p> <ol> <li>Molded mouse phantom (MBD CBCT)    Custom physical phantom with BaSO\u2084-doped skeleton, PLA lungs, and silicone soft tissue, scanned on the low-power laboratory CBCT system to validate the full acquisition\u2013preprocessing\u2013reconstruction pipeline.</li> </ol> <p></p> <ol> <li>Synthetic Digimouse ATLAS (USC)    Fully segmented digital mouse model converted to a CT-like attenuation volume. Synthetic cone-beam projections were generated with a cone-beam geometry and realistic noise to obtain a ground-truth benchmark.</li> </ol> <p></p> <ol> <li>Real preclinical mouse CT (UKMZ)    High-resolution cone-beam micro-CT datasets acquired on a Yxlon Cheetah system (full 360\u00b0 and limited 190\u00b0 trajectories), including tumor-bearing mice, used to assess reconstruction behaviour under realistic anatomy, noise, and system-specific artefacts.</li> </ol> <p></p>"},{"location":"experiments/experiments/#software-hardware","title":"Software &amp; Hardware","text":"<p>All reconstructions were performed on a Windows 11 laptop using WSL2 (Ubuntu 20.04) and an NVIDIA RTX 4060 (8 GB VRAM):</p> <ul> <li>Development in VS Code (WSL remote) with Git-based workflow  </li> <li> <p>Conda environment with:</p> <ul> <li>Python 3.9  </li> <li>CUDA-enabled PyTorch and torchvision </li> <li>NumPy, SciPy, scikit-image, SimpleITK, OpenCV, Matplotlib, pyvista  </li> <li>R\u00b2-Gaussian implementation (Zha et al.)  </li> <li>TIGRE toolbox for FDK reconstruction  </li> </ul> </li> </ul> <p>GPU memory limitations required using both full-resolution (\u2248630\u00b3) and reduced-resolution (256\u00b3) volumes and limiting the maximum number of Gaussians.</p>"},{"location":"experiments/experiments/#unified-reconstruction-workflow","title":"Unified Reconstruction Workflow","text":"<p>All datasets followed the same basic workflow:</p> <ol> <li> <p>Projections</p> <ul> <li>Physical scans (phantom, UKMZ animal data), or  </li> <li>Synthetic forward projections from the Digimouse volume.</li> </ul> </li> <li> <p>Preprocessing</p> <ul> <li>Flat-field correction (dark / open beam)  </li> <li>Log-conversion to line integrals  </li> <li>Intensity normalization and rotation-axis alignment  </li> <li>Projection downsampling when required for GPU feasibility</li> </ul> </li> <li> <p>Reconstruction</p> <ul> <li>FDK (TIGRE) as analytic baseline  </li> <li>R\u00b2-Gaussian as optimization-based method with tuned hyperparameters and a capped Gaussian budget</li> </ul> </li> <li> <p>Evaluation</p> <ul> <li>Full-volume and inner-volume PSNR/SSIM (where a reference volume was available)  </li> <li>Sparse-view and limited-angle protocols on UKMZ data  </li> <li>Qualitative slice inspection in a custom multi-planar viewer:</li> </ul> </li> </ol> <p></p>"},{"location":"experiments/experiments/#protocols-overview-only","title":"Protocols (Overview Only)","text":"<ul> <li>Phantom: full 360\u00b0 scans, 720 projections, 256\u00b3 reconstructions with FDK and R\u00b2-Gaussian; used mainly for qualitative validation and geometry/preprocessing checks.</li> <li>Digimouse: 256\u00b3 volume, synthetic noisy projections, FDK and R\u00b2-Gaussian comparison using full-volume and inner-volume PSNR/SSIM against the known ground truth.</li> <li>UKMZ full-angle: 360\u00b0 / 2000-projection datasets at 630\u00d7630 detector resolution; sparse-view experiments (few to many projections) at 256\u00b3 and 630\u00b3, with FDK as pseudo ground truth.</li> <li>UKMZ limited-angle (190\u00b0): evaluation of reconstruction stability under incomplete angular coverage across varying projection counts and angular ranges.</li> </ul>"},{"location":"experiments/results/","title":"Results (Condensed)","text":"<p>Condensed Version</p> <p>The content below is a shortened summary of the original, full-length analysis. Only the key findings are included here. For complete figures, reconstruction curves, and parameter evaluations, refer to the thesis PDF.</p>"},{"location":"experiments/results/#hardware-constraints","title":"Hardware Constraints","text":"<p>All reconstructions were performed on an RTX 4060 Laptop GPU (8 GB VRAM). Compared to the original R\u00b2-Gaussian paper (RTX 3090, 24 GB VRAM), the limited memory strongly restricted:</p> <ul> <li>usable volume size (mostly 256\u00b3, only constrained 630\u00b3),</li> <li>maximum Gaussians (stable limit \u2248 200k),</li> <li>number of iterations (\u2264 25k),</li> <li>densification duration (\u2264 5k iterations),</li> <li>projection size (downsampled 630\u00b2 \u2192 210\u00b2).</li> </ul> <p>Most failures were caused by voxelizer memory allocation during PSNR/SSIM evaluation:</p> <ul> <li><code>RuntimeError: CUDA out of memory</code></li> <li><code>RuntimeError: numel: integer multiplication overflow</code></li> </ul> <p>A stable configuration was established through projection downsampling, early densification stop, Gaussian count limits, and reduced volume sizes.</p>"},{"location":"experiments/results/#molded-phantom","title":"Molded Phantom","text":"<p>The custom 3-component phantom (silicone body, PLA lungs, BaSO\u2084-doped SLA skeleton) was successfully fabricated, though some elements shifted during curing and air bubbles remained.</p> <ul> <li>R\u00b2-Gaussian and FDK reconstructions both reflected these imperfections.</li> <li>BaSO\u2084 doping increased skeletal attenuation as expected.</li> <li>Minor geometric misalignment and projection shifts were visible in both methods.</li> </ul> <p></p>"},{"location":"experiments/results/#digimouse-atlas-synthetic-data","title":"Digimouse Atlas (Synthetic Data)","text":"<p>Used to evaluate sparse-view behaviour with a true ground truth.</p> <p>Sparse-view performance (25\u201375 projections):</p> <ul> <li>R\u00b2-Gaussian: PSNR \u2248 29 dB, SSIM \u2248 0.85 (stable across projection counts)  </li> <li>FDK: Strong degradation in sparse view (PSNR \u2248 10\u201315 dB)</li> </ul> <p>However, large homogeneous regions in Digimouse caused R\u00b2-Gaussian to produce grainy textures, indicating difficulty representing uniform tissues with limited Gaussian capacity.</p> <p></p>"},{"location":"experiments/results/#preclinical-mouse-data-ukmz","title":"Preclinical Mouse Data (UKMZ)","text":""},{"location":"experiments/results/#rotation-axis-alignment","title":"Rotation-Axis Alignment","text":"<p>A horizontal shift of 5 px (full-angle) and 6 px (limited-angle) maximised reprojection PSNR/SSIM and removed double edges.</p> <p></p>"},{"location":"experiments/results/#small-volume-reconstructions-2563","title":"Small-Volume Reconstructions (256\u00b3)","text":"<ul> <li>Sparse-view (&lt;100 projections):   R\u00b2-Gaussian outperformed FDK (inner-volume PSNR \u2248 38 dB, SSIM \u2248 0.95).</li> <li>Beyond ~150 projections:   FDK surpassed R\u00b2-Gaussian and continued improving, while R\u00b2-Gaussian saturated due to Gaussian-count limits.</li> <li>TV regularisation: negligible effect on reconstruction quality.</li> <li>Intensity-matching strategies: negligible influence.</li> </ul>"},{"location":"experiments/results/#full-volume-reconstructions-6303","title":"Full-Volume Reconstructions (630\u00b3)","text":"<p>Under memory-feasible settings:</p> <ul> <li>R\u00b2-Gaussian again dominated the very sparse-view regime (&lt;100 projections).</li> <li>FDK dominated moderate and dense sampling.</li> <li>R\u00b2-Gaussian saturated at \u2248 37\u201338 dB PSNR and SSIM \u2248 0.95.</li> </ul> <p></p> <p></p>"},{"location":"experiments/results/#limited-angle-reconstructions-190","title":"Limited-Angle Reconstructions (190\u00b0)","text":"<p>R\u00b2-Gaussian showed improved robustness in extreme limited-angle settings:</p> <ul> <li>For &lt;90\u2013120\u00b0 coverage or very few projections, R\u00b2-Gaussian produced fewer angular artefacts than FDK.</li> <li>With increasing angular range or projection count, FDK quickly surpassed R\u00b2-Gaussian.</li> <li>R\u00b2-Gaussian performance remained capped at \u2248 27 dB / 0.85 SSIM due to the same representational limits observed earlier.</li> </ul> <p></p> <p></p>"},{"location":"install/install/","title":"Installation Guide: R\u00b2-Gaussian","text":"<p>This page describes how to install and set up the R\u00b2-Gaussian reconstruction pipeline on a Windows 11 machine using WSL2 (Ubuntu 20.04), CUDA 11.8, Miniconda, and PyTorch.</p> <p>Internal usernames, passwords, and proprietary directory structures have been replaced with placeholders. </p> <p>Author: M. Handta Compatible OS: Windows 11 + WSL2 (Ubuntu 20.04) GPU: NVIDIA GPU with CUDA support (tested with RTX 3090 in the original paper) </p>"},{"location":"install/install/#prerequisites","title":"Prerequisites","text":"<p>Already correctly installed and functioning:</p> <ul> <li>Windows 11  </li> <li>Visual Studio Code  </li> <li>NVIDIA GPU Driver  </li> </ul> <p>Everything else will be explained below.</p>"},{"location":"install/install/#wsl2-installation","title":"WSL2 Installation","text":""},{"location":"install/install/#1-enable-windows-features","title":"1. Enable Windows Features","text":"<p>Open Windows Features and activate:</p> <ul> <li>Windows Subsystem for Linux</li> <li>Virtual Machine Platform</li> </ul> <p>Check both boxes, save, and restart your PC (mandatory).</p> <p></p>"},{"location":"install/install/#2-install-wsl-via-powershell","title":"2. Install WSL via PowerShell","text":"<p>Run PowerShell as Administrator:  </p> <pre><code>    wsl --install\n</code></pre> <p>After installation, set username and password:</p> <ul> <li>User: yourusername</li> <li>Password: yourpassword</li> </ul>"},{"location":"install/install/#3-additional-wsl-settings-os-version","title":"3. Additional WSL Settings / OS Version","text":"<p>Run again in PowerShell (Admin): </p> <pre><code>    wsl --set-default-version 2\n</code></pre> <p>Info</p> <p>\u201cWe tested the code on Ubuntu 20.04 with an RTX 3090 GPU.\u201d                \u2013 R2-gaussian Authors</p> <p>In the Microsoft Store: Search and install Ubuntu 20.04.06 LTS.</p> <p></p> <p>You can now start Linux either via: \u2022   PowerShell:   <code>wsl</code> \u2022   Start Menu: Ubuntu 20.04.06 LTS</p>"},{"location":"install/install/#cuda-toolkit-installation","title":"CUDA Toolkit Installation","text":""},{"location":"install/install/#1-check-existing-cuda-installation","title":"1. Check Existing CUDA Installation","text":"<p>Open Ubuntu (WSL) terminal: </p> <pre><code>    nvcc --version\n</code></pre> <p>If CUDA 11.6 or 11.8 (recommended by Gaussian Splatting authors) is installed, proceed to Git/VS Code setup.</p> <p>If an older / unwanted version is installed, remove it:</p> <pre><code>    sudo apt purge -y \"cuda*\" \"nvidia-cuda*\" \"nsight*\"\n\n    sudo apt autoremove -y\n\n    sudo rm -rf /usr/local/cuda*\n</code></pre> <p>Check removal: <pre><code>    ls /usr/local | grep cuda\n</code></pre> Check Nvidia driver: <pre><code>    nvidia-smi\n</code></pre></p>"},{"location":"install/install/#2-install-cuda-toolkit-118","title":"2. Install CUDA Toolkit 11.8","text":"<p>Go to: CUDA Toolkit Archive | NVIDIA Developer</p> <p>Select CUDA 11.8 for Ubuntu 20.04 and follow instructions.</p> <p></p> <p>Verified working commands:</p> <p>Install prerequisites</p> <pre><code>    sudo apt update\n\n    sudo apt install -y wget gnupg2 ca-certificates\n</code></pre> <p>Add NVIDIA CUDA repo for Ubuntu 20.04</p> <pre><code>    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\n\n    sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\n\n    wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda-repo-ubuntu2004-11-8-local_11.8.0-520.61.05-1_amd64.deb\n\n    sudo dpkg -i cuda-repo-ubuntu2004-11-8-local_11.8.0-520.61.05-1_amd64.deb\n\n    sudo cp /var/cuda-repo-ubuntu2004-11-8-local/cuda-*-keyring.gpg /usr/share/keyrings/\n\n    sudo apt update\n</code></pre> <p>IMPORTANT: </p> <pre><code>    sudo apt install -y cuda-toolkit-11-8\n</code></pre> <p>This installs nvcc, headers, and libraries.</p>"},{"location":"install/install/#3-add-cuda-to-path","title":"3. Add CUDA to PATH","text":"<p>Edit your bashrc:</p> <pre><code>    nano ~/.bashrc\n</code></pre> <p>Add to bottom:</p> <pre><code>    export PATH=/usr/local/cuda-11.8/bin:$PATH\n    export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH\n</code></pre> <p>Apply:</p> <pre><code>    source ~/.bashrc\n</code></pre>"},{"location":"install/install/#4-verify-cuda-installation","title":"4. Verify CUDA Installation","text":"<pre><code>    nvcc --version\n</code></pre> <p>Expected: </p> <pre><code>Cuda compilation tools, release 11.8, V11.8.xxx\n</code></pre> <p>Check driver:</p> <pre><code>    nvidia-smi\n</code></pre>"},{"location":"install/install/#miniconda-git-vscode-setup","title":"Miniconda, Git &amp; VScode setup","text":""},{"location":"install/install/#1-install-miniconda","title":"1. Install Miniconda","text":"<p>Download Miniconda (Linux x86_64, recommended over Anaconda)</p> <pre><code>    cd ~\n\n    wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n</code></pre> <p>Run installer</p> <pre><code>    bash Miniconda3-latest-Linux-x86_64.sh\n</code></pre> <p>During installation: - Accept license - Default installation path (press ENTER) - Initialize Miniconda \u2192 yes</p> <p>Reload:</p> <pre><code>    source ~/.bashrc\n</code></pre> <p>Verify: <pre><code>    conda --version\n</code></pre></p>"},{"location":"install/install/#2-configure-conda-important","title":"2. Configure conda (important)","text":"<pre><code>    conda config --set auto_activate_base false\n\n    conda config --set channel_priority strict\n</code></pre> <p>Activate: </p> <pre><code>    conda activate \n</code></pre> <p>Check Python path:</p> <pre><code>    which python\n</code></pre> <p>Expected:</p> <pre><code>/home/mbdusr/miniconda3/envs/torch118/bin/python\n</code></pre> <p>If you see <code>/mnt/c/...</code> \u2192 wrong, using Windows Python.</p>"},{"location":"install/install/#3-install-git","title":"3. Install Git","text":"<p>WSL needs its own Git installation:</p> <pre><code>    sudo apt update\n\n    sudo apt install -y git\n\n    git \u2013version\n</code></pre>"},{"location":"install/install/#4-configure-vs-code-for-wsl","title":"4. Configure VS Code for WSL","text":"<p>Do not install VS Code inside Ubuntu.</p> <p>On Windows:</p> <ul> <li>Open VS Code</li> <li>Install extension \u201cWSL\u201d (Microsoft)</li> </ul> <p>Open VS Code from Ubuntu:</p> <pre><code>    cd ~\n\n    code .\n</code></pre> <p>VS Code Server installs automatically. Bottom left will show: WSL: Ubuntu-20.04</p>"},{"location":"install/install/#cloning-the-r2-gaussian-repository","title":"Cloning the R2-Gaussian Repository","text":"<p>Repo: R2-Gaussian</p> <p>Clone repo (WSL) Always clone inside Linux home, not Windows folders.</p> <pre><code>    cd ~\n\n    git clone https://github.com/Ruyi-Zha/r2_gaussian.git --recursive\n</code></pre> <p>Open in VS Code</p> <pre><code>    cd r2_gaussian\n\n    code .\n</code></pre>"},{"location":"install/install/#install-submodules-and-tigre-toolbox","title":"Install submodules and Tigre-toolbox","text":"<p>Below is the link to the installation guide provided by the R2-Gaussian authors:</p> <p>R2-gaussian Installation</p> <p>If their instructions do not work, follow the full detailed guide below.</p> <p>If you did not clone the repository with <code>--recursive</code>, do it now:</p> <pre><code>    git clone https://github.com/Ruyi-Zha/r2_gaussian.git --recursive\n</code></pre>"},{"location":"install/install/#1-create-r2_gaussian-conda-environment","title":"1. Create r2_gaussian Conda Environment","text":"<p>First create a dedicated conda environment:</p> <pre><code>    conda create -n r2_gaussian python=3.9 -y\n\n    conda activate r2_gaussian\n</code></pre> <p>Install PyTorch (CUDA 11.8 compatible):</p> <pre><code>    pip install torch==2.1.2+cu118 torchvision==0.16.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\n</code></pre> <p>Install all Python requirements from the repo:</p> <pre><code>    pip install -r requirements.txt\n</code></pre> Info <p>If you forgot to clone recursively earlier (submodules missing), execute:</p> <pre><code>    git submodule update --init --recursive) \n</code></pre> <p>Check:</p> <pre><code>    ls r2_gaussian/submodules/simple-knn\n</code></pre> <p>You should see things like: <pre><code>    setup.py     simple_knn/     src/\n</code></pre></p>"},{"location":"install/install/#2-install-submodules-cuda-extensions","title":"2. Install Submodules (CUDA Extensions)","text":"<p>The repository contains two CUDA-based Python submodules that must be built manually:</p> <ul> <li>simple-knn</li> <li>xray-gaussian-rasterization-voxelization</li> </ul> <p>These must be installed editable and with build isolation disabled, otherwise Python will try to create a temporary build environment and will not find your Torch installation, resulting in: </p> <pre><code>ModuleNotFoundError: No module named 'torch' \n</code></pre> <p>To install correctly, run: </p> <pre><code>    pip install -e r2_gaussian/submodules/simple-knn  --no-build-isolation\n\n    pip install -e r2_gaussian/submodules/xray-gaussian-rasterization-voxelization --no-build-isolation\n</code></pre> <p>Why <code>--no-build-isolation</code> is essential</p> <p>By disabling build isolation:</p> <ul> <li>the build system sees your active conda environment,</li> <li>torch and its CUDA headers are visible,</li> <li>the extension compiles against the correct CUDA toolkit,</li> <li>compatibility issues with PyTorch + CUDA are avoided.</li> </ul> <p>This is a common requirement for research repositories containing custom CUDA kernels.</p> <p>Verify successful installation:</p> <pre><code>    Python -c \u201cimport simple_knn; print(\u2018simple_knn OK\u2019)\u201d \n</code></pre>"},{"location":"install/install/#3-install-tigre-toolbox","title":"3. Install TIGRE toolbox","text":"<p>R2-Gaussian relies on parts of the TIGRE toolbox for projection / reconstruction operations.</p> <p>You need to install TIGRE in Python mode with build isolation disabled. Download the official TIGRE release (v2.3):</p> <pre><code>    wget https://github.com/CERN/TIGRE/archive/refs/tags/v2.3.zip\n\n    unzip v2.3.zip\n</code></pre> <p>Install:</p> <pre><code>    pip install TIGRE-2.3/Python --no-build-isolation\n</code></pre> <p>This installs the Python interface without re-compiling unnecessary MATLAB components.</p>"},{"location":"install/install/#4-add-submodule-to-python-path","title":"4. Add Submodule to Python PATH","text":"<p>Even after pip installation, you may encounter:</p> <pre><code>ModuleNotFoundError: No module named 'simple_knn'\n</code></pre> <p>This happens because the repository\u2019s internal module structure expects the repository root to be available in PYTHONPATH, and pip alone does not fully solve this for all relative imports.</p> <p>To prevent this issue, you need to add the submodules to your Python search path.</p> <p>Temporary fix (only for current terminal session)</p> <p>Run:</p> <pre><code>    export PYTHONPATH=\"$HOME/Bachelorthesis/r2_gaussian/r2_gaussian/submodules/simple-knn:$HOME/Bachelorthesis/r2_gaussian/r2_gaussian/submodules/xray-gaussian-rasterization-voxelization\"\n</code></pre> <p>This works until you close the terminal.</p> <p>Permanent Fix (recommended)</p> <p>Open .bashrc</p> <pre><code>    nano ~/.bashrc\n</code></pre> <p>Add the following single-line entry at the very bottom:</p> <pre><code>    # R2 Gaussian submodules\n    export PYTHONPATH=\"$HOME/r2_gaussian/r2_gaussian/submodules/simple-knn:$HOME/r2_gaussian/r2_gaussian/submodules/xray-gaussian-rasterization-voxelization:$PYTHONPATH\"\n</code></pre> <p>Important details:</p> <ul> <li>Must be one line (avoid unwanted line breaks).</li> <li>Keep :$PYTHONPATH at the end \u2192 preserves existing search paths.</li> <li>Use absolute paths, otherwise imports may fail depending on where Python is executed.</li> </ul> <p>Save and exit: </p> <ul> <li>Ctrl+O \u2192 Enter</li> <li>Ctrl+X</li> </ul> <p>Reload:</p> <pre><code>    source ~/.bashrc\n</code></pre> <p>Verify permanent accessibility:</p> <pre><code>    python -c \"import simple_knn; print('simple_knn OK')\"\n</code></pre> <p>Author: Manuel Handta</p> <p>Version: 1.0 \u2013 December 2025</p> <p>Purpose: Installation documentation for R\u00b2-Gaussian reconstruction pipeline</p>"},{"location":"usage/usage/","title":"Workflow Basics","text":"<p>What this page covers</p> <p>This section gives a compact, practical workflow for running R\u00b2-Gaussian on your own CBCT data. It complements -not replaces- the official documentation from the authors: R\u00b2-Gaussian Algorithm</p> <p>Open WSL, then open VS Code, activate environment, and cd into repository. </p> <p>Your prompt should look like:</p> <pre><code>(r2_gaussian) yourusername@DESKTOP-PC:~/r2_gaussian$\n</code></pre>"},{"location":"usage/usage/#1-generate-data-projections-projection-folder","title":"1. Generate Data (Projections \u2192 Projection Folder)","text":"<p>Use the script for UKMZ-style real datasets:</p> <pre><code>    python ./data_generator/real_dataset/generate_data_ukmz.py \\\n        --data ./data/real_dataset/ukm_data \\\n        --output ./data/real_dataset/ukm_data_proj\n</code></pre> <p>This produces a projection folder structured exactly as expected by the training script.</p>"},{"location":"usage/usage/#2-initialize-data","title":"2. Initialize Data","text":"<p>Why initialization matters (from authors)</p> <p>Initialization is essential for all 3DGS-based reconstruction methods. The authors initialize Gaussians by sampling from a noisy FDK reconstruction. Default code assumes densities in the range [0, 1] \u2014 adjust if needed.</p> <p>Run initialization:</p> <pre><code>    python initialize_pcd.py \\\n        --data ./data/real_dataset/ukm_data_proj \\\n        --recon_method random\n</code></pre> <p>To evaluate initialization quality:</p> <pre><code>    python initialize_pcd.py \\\n        --data ./data/... \\\n        --evaluation\n</code></pre> <p>This produces the <code>*.npy</code> initialization file required for training.</p>"},{"location":"usage/usage/#3-visualize-scene-script-optional-but-recommended","title":"3. Visualize Scene Script (Optional but Recommended)","text":"<p>Useful to quickly inspect geometry, projection alignment, and initial Gaussians.</p> <pre><code>    python scripts/visualize_scene.py -s ./data/real_dataset/ukm_data_proj\n</code></pre>"},{"location":"usage/usage/#4-train-data","title":"4. Train data","text":"<p>Basic training command (my tuned parameters):</p> <pre><code>    python train.py \\\n        -s ./data/real_dataset/ukm_data_proj/ \\\n        --eval \\\n        --test_iterations 1000 2000 5000 \\\n        --iteration 5000 \\\n        --max_num_gaussians 200000 \\\n        --scale_min 0.002 \\\n        --scale_max 0.2 \\\n        --densify_until_iter 5000\n</code></pre> <p>Additional guidance from original authors</p> <p>Tips from the official repo</p> <ul> <li>If training is slow or too many Gaussians are generated \u2192 increase --densify_grad_threshold</li> <li>To disable densification completely \u2192 --densify_until_iter 0</li> <li>The entire scene is automatically scaled to [-1, 1]\u00b3 for stability</li> <li>Training time depends heavily on object sparsity</li> <li>For many datasets, meaningful results appear before full convergence</li> </ul> <p>Train all datasets in a folder:</p> <pre><code>    python scripts/train_all.py \\\n        --source data/... \\\n        --output output/... \\\n        --device 0\n</code></pre>"},{"location":"usage/usage/#5-evaluate-optional","title":"5. Evaluate (Optional)","text":"<p>During training, evaluation metrics (PSNR/SSIM) are written into TensorBoard.</p> <p>Full evaluation:</p> <pre><code>    python test.py -m path/to/trained_model\n</code></pre>"},{"location":"usage/usage/#6-using-your-own-data","title":"6. Using Your Own Data","text":"<p>The authors support:</p> <ul> <li>cone-beam</li> <li>parallel-beam configurations</li> </ul> <p>If you only have volumes, generate projections (their instructions apply).</p> <p>If you only have X-ray projections, convert to:</p> <ul> <li>meta_data.json format, or</li> <li>*.pickle (SAX-NeRF format)</li> </ul> <p>Then run:</p> <pre><code>    python initialize_pcd.py --data &lt;your_dataset&gt;\n    python train.py -s &lt;your_dataset&gt;\n</code></pre>"},{"location":"usage/usage/#final-notes","title":"Final Notes","text":"<p>This workflow is adapted for CBCT, UKMZ datasets, and 8 GB GPU constraints.</p> <p>Always cross-check with the latest official documentation: R\u00b2-Gaussian Algorithm</p>"}]}